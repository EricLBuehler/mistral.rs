searchState.loadedDescShard("mistralrs_quant", 0, "Device/configurable intelligent matrix multiplication\nQuantized method for a quantized matmul.\nReal (for Metal) and Fake (for CUDA)\nUsed to gate access to quantizing onto the host device\nOffset for the quant type. UQFF always serializes the …\nAdd a delta weight from LoRA to the weights. This should …\nIf the quant is backed by a qmatmul.\nBegin tracking stats into an ImatrixLayerStats\nWeight dtype and device\nEnd tracking stats into an ImatrixLayerStats. Returns the …\nCompute matmul of <code>self</code> and <code>a</code>. <code>self</code> should contain the …\nCompute matmul of <code>self</code> and <code>a</code>. <code>self</code> should contain the …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nStatic LoRA in the style of Phi-4 multimodal. Only when …\nCompute matrix-matrix product.\nCompute matrix-matrix product. The result will be divided …\nCompute matrix-matrix product. The result will be divided …\nFactor by which the weight size is reduced over the given …\nCompute quantized matrix-matrix product.\nCompute quantized matrix-matrix product.\nQuantize the model into HQQ\nIf a quantized method, return the activation dtype.\nNOT meant for external calling\nFused batch matmul + add + Relu/Gelu activation using …\nFused batch matmul + add + Relu/Gelu activation using …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThis layer has a weight that is parallelized along the …\nThis layer has no parallelization\nThis layer has a weight that is parallelized along the …\nCompute the appropriate KV shard. This handles KV head …\nCompute the number of KV groups, taking into account KV …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe Client holds its persistent connection inside a Mutex …\nThe Server maintains persistent connections.\nBroadcasts the given ID over all persistent connections.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nBinds the listener and then accepts exactly <code>n_nodes</code> …\nReceives the broadcasted ID from the persistent stream.\nApply Rotary position encoding inplace\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreates a wrapper around multiple memory mapped file and …\nCreates a wrapper around a memory mapped file and …\nInitializes a <code>VarBuilder</code> that retrieves tensors stored in …")