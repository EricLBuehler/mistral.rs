searchState.loadedDescShard("mistralrs_server", 0, "Chat template file with a JINJA file with <code>messages</code>, …\nUse CPU only\nEnable searching compatible with the OpenAI …\nEnable thinking for interactive mode and models that …\nReturns the argument unchanged.\nIn-situ quantization to apply.\nEnter interactive mode instead of serving a chat server.\nCalls <code>U::from(self)</code>.\nExplicit JINJA chat template file (.jinja) to be used. If …\nLog all responses and requests to this file\nMaximum running sequences at any time. If the …\nModel selector\nUse no KV cache.\nDisable PagedAttention on CUDA. Because PagedAttention is …\nNOTE: This can be omitted to use automatic device mapping! …\nEnable PagedAttention on Metal. Because PagedAttention is …\nBlock size (number of tokens per block) for …\nGPU memory to allocate for KV cache with PagedAttention in …\nPercentage of GPU memory to utilize after allocation of KV …\nTotal context length to allocate the KV cache for (total …\nPort to serve on.\nNumber of prefix caches to hold on the device. Other …\nNumber of tokens to batch the prompt step into. This can …\nSpecify a Hugging Face model ID for a BERT model to assist …\nInteger seed to ensure reproducible random number …\nIP to serve on. Defaults to “0.0.0.0”\nSource of the token for authentication. Can be in the …\nIf a sequence is larger than the maximum model length, …\nRegex string used to extract image URLs from prompts.")