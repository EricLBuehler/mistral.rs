searchState.loadedDescShard("mistralrs_server_core", 0, "<strong>mistral.rs server core</strong>\nChat Completions functionality and route handler.\nmistral.rs instance for server builder.\nmistral.rs server router builder.\nOpenAI compatible functionality.\nOpenAPI doc functionality.\nCustom types used in mistral.rs server core.\nGeneral utilities.\nRepresents different types of chat completion responses.\nDefault buffer size for the response channel used in …\nDefault keep-alive interval for Server-Sent Events (SSE) …\nInternal server error\nComplete JSON response for non-streaming requests\nModel error with partial response data\nA callback function that processes streaming response …\nA callback function that is executed when the streaming …\nServer-Sent Events streaming response\nA streaming response handler.\nRequest validation error\nOpenAI-compatible chat completions endpoint handler.\nCreates a SSE streamer for chat completions with optional …\nCreates a channel for response communication.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGets the keep-alive interval for SSE streams from …\nHelper function to handle chat completion errors and …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConverts the chat completion responder into an HTTP …\nMatches and processes different types of model responses …\nParses and validates a chat completion request.\nPolls the stream for the next Server-Sent Event.\nProcesses non-streaming chat completion responses.\nSends a request to the model processing pipeline.\nA builder for creating a the mistral.rs instance with …\nBuilds the configured mistral.rs instance.\nCreates a new builder with default configuration.\nProvides the default values used for the mistral.rs …\nReturns the argument unchanged.\nCreates a BERT embedding model configuration for search …\nCalls <code>U::from(self)</code>.\nCreates a new <code>MistralRsForServerBuilder</code> with default …\nSets the chat template configuration.\nSets the chat template configuration if provided.\nSets whether to force CPU-only execution.\nSets the Candle device to use for model execution.\nSets whether to enable web search functionality.\nSets the in-situ quantization method.\nSets the in-situ quantization method if provided.\nSets whether to run in interactive mode.\nSets an explicit JINJA chat template file.\nSets an explicit JINJA chat template file if provided.\nSets the logging configuration.\nSets the logging configuration if provided.\nSets the maximum number of concurrent sequences.\nSets the model to be used.\nSets whether to disable the key-value cache.\nSets whether to disable PagedAttention on CUDA devices.\nSets the device layer mapping\nSets the device layer mapping if provided.\nSets whether to enable PagedAttention.\nSets the block size for PagedAttention.\nSets the block size for PagedAttention if provided.\nSets the GPU memory allocation for PagedAttention KV cache.\nSets the GPU memory allocation for PagedAttention KV cache …\nSets the percentage of GPU memory to utilize for …\nSets the percentage of GPU memory to utilize for …\nSets the total context length for KV cache allocation.\nSets the total context length for KV cache allocation if …\nSets the number of prefix caches to hold on the device.\nSets the prompt chunking size.\nSets the prompt chunking size if provided.\nSets the BERT model for web search assistance.\nSets the random seed for deterministic model behavior.\nSets the random seed if provided.\nSets the token source for authentication.\nSets whether to truncate sequences that exceed the maximum …\nThis is the axum default request body limit for the …\nA builder for creating a mistral.rs server router with …\nBuilds the configured axum router.\nCreates a new builder with default configuration.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreates a new <code>MistralRsServerRouterBuilder</code> with default …\nSets the CORS allowed origins.\nSets a base path prefix for all routes.\nConfigures whether to include OpenAPI doc routes.\nSets the axum default request body limit.\nSets the shared mistral.rs instance\nHigh-quality lossy compression, commonly used in mobile …\nAudio format options for speech generation responses.\nChat completion request following OpenAI’s specification\nLegacy OpenAI compatible text completion request\nLossless compression, larger file sizes but good audio …\nRepresents a function call made by the assistant\nGrammar specification for structured generation\nImage generation request\nJSON schema grammar\nStructured response following a JSON schema\nJSON Schema for structured responses\nLark parser grammar\nLLGuidance grammar\nRepresents a single message in a conversation\nMessage content that can be either simple text or complex …\nInner content structure for messages that can be either a …\nModel information metadata about an available mode\nCollection of available models\nWidely compatible, lossy compression, good for web …\nMultiple possible stop sequences\nGood compression efficiency, ideal for real-time …\nRaw audio data, requires additional format specification\nRegular expression grammar\nResponse format for model output\nSingle stop sequence\nSpeech generation request\nStop token configuration for generation\nFree-form text response\nRepresents a tool call made by the assistant\nUncompressed, largest file sizes but maximum compatibility\nGenerate the appropriate MIME content type string for this …\nThe message content\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nThe function call details\nThe text content to convert to speech.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe TTS model to use for audio generation.\nThe name of the function to call\nThe function arguments\nThe desired audio format for the generated speech.\nThe role of the message sender (“user”, “assistant”…\nOptional list of tool calls\nThe type of tool being called\nThis is used to generate the OpenAPI docs. The mistral.rs …\nThis is the <code>SharedMistralRsState</code> that has been extracted …\nThis is the underlying instance of mistral.rs.\nParses and loads an image from a URL, file path, or data …")