searchState.loadedDescShard("mistralrs_bench", 0, "Number of concurrent requests to run. Default is 1\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nIn-situ quantization to apply.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nModel\nNumber of generations tokens to run.\nNumber of prompt tokens to run.\nDisable PagedAttention on CUDA. Because PagedAttention is …\nNOTE: This can be omitted to use automatic device mapping! …\nEnable PagedAttention on Metal. Because PagedAttention is …\nBlock size (number of tokens per block) for …\nGPU memory to allocate for KV cache with PagedAttention in …\nPercentage of GPU memory to utilize after allocation of KV …\nTotal context length to allocate the KV cache for (total …\nNumber of tokens to batch the prompt step into. This can …\nNumber of times to repeat each test.\nInteger seed to ensure reproducible random number …\n<code>ToString::to_string</code>, but without panic on OOM.\n<code>ToString::to_string</code>, but without panic on OOM.")