# Documentation

## API
- [HTTP API](HTTP.md) - OpenAI-compatible HTTP server endpoints

## Models
- Image generation [models](IMAGEGEN_MODELS.md)
- Vision [models](VISION_MODELS.md)

- [FLUX](FLUX.md)
- [Gemma 2](GEMMA2.md)
- [Idefics 2](IDEFICS2.md)
- [LLaVA](LLaVA.md)
- [Phi 3.5 MoE](PHI3.5MOE.md)
- [Phi 3.5 Vision](PHI3V.md)
- [Phi 4 Multimodal](PHI4MM.md)
- [Llama 3.2 Vision](VLLAMA.md)
- [Qwen2-VL](QWEN2VL.md)
- [Idefics 3 and Smol VLM](IDEFICS3.md)
- [DeepSeek V2](DEEPSEEKV2.md)
- [DeepSeek V3](DEEPSEEKV3.md)
- [MiniCPM-O 2.6](MINICPMO_2_6.md)
- [Gemma 3](GEMMA3.md)
- [Mistral 3](MISTRAL3.md)
- [Llama 4](LLAMA4.md)
- [Qwen 3](QWEN3.md)
- [Qwen 3 VL](QWEN3VL.md)
- [Gemma 3n](GEMMA3N.md)
- [GLM4](GLM4.md)
- [SmolLM3](SMOLLM3.md)
- [GPT-OSS](GPT_OSS.md)
- [Dia (Speech)](DIA.md)
- [Embeddings overview](EMBEDDINGS.md)
- [EmbeddingGemma](EMBEDDINGGEMMA.md)
- [Qwen3 Embedding](QWEN3_EMBEDDING.md)

## Adapters
- [Docs](ADAPTER_MODELS.md)
- [X-LoRA non-granular](NON_GRANULAR.md)
- [LoRA and X-LoRA examples](LORA_XLORA.md)
- [AnyMoE](ANYMOE.md) - Create MoE models from dense models

## Quantization
- [Docs](QUANTS.md)
- [ISQ](ISQ.md)
- [UQFF](UQFF.md)
- [Topology](TOPOLOGY.md)
- [Importance Matrix (ISQ Enhancement)](IMATRIX.md)

## Multi-Model & Runtime Management
- [Multi-model support](multi_model/README.md) - Load multiple models, switch between them, unload/reload at runtime

## Other
- [Chat templates and tokenizers](CHAT_TOK.md)
- [Paged Attention](PAGED_ATTENTION.md)
- [Flash Attention](FLASH_ATTENTION.md)
- [Sampling](SAMPLING.md)
- [TOML selector](TOML_SELECTOR.md)
- [Tool calling](TOOL_CALLING.md)
- [Web Search](WEB_SEARCH.md)
- [MatFormer](MATFORMER.md) - Dynamic model sizing
- [MCP Client](mcp/README.md)
- [MCP Server](mcp/server.md)

## Cross-device inference
- [Device mapping](DEVICE_MAPPING.md)
- [Topology](TOPOLOGY.md)
