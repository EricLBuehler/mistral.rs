window.SIDEBAR_ITEMS = {"constant":["MULTI_LORA_DELIMITER","UQFF_QUANT_TYPE_OFFSET"],"enum":["AfqBits","AfqGroupSize","BnbQuantType","DistributedKind","HqqAxis","HqqBits","IsqType","QuantMethodConfig","QuantizeOntoDropGuard","QuantizedConfig","QuantizedSerdeType"],"fn":["apply_immediate_isq","blockwise_fp8_moe","clear_applied_loras","clear_immediate_isq","fp8_blockwise_dequantize","fp8_blockwise_quantize","fp8_vector_dequantize","fp8_vector_quantize","get_applied_loras","get_immediate_isq","immediate_isq_match","linear","linear_b","linear_no_bias","linear_no_bias_static_lora","push_applied_lora","set_immediate_isq","set_immediate_isq_with_overrides","should_apply_immediate_isq"],"mod":["cublaslt","distributed","gemv","log","rotary","safetensors"],"struct":["AfqLayer","BlockwiseFP8Linear","BnbLinear","BnbQuantParams","CollectedImatrixData","Convolution","DummyLayer","FP8Linear","GgufMatMul","GptqLayer","HqqConfig","HqqLayer","ImatrixLayerStats","ImmediateIsqMatch","ImmediateIsqOverride","ImmediateIsqParams","LoraAdapter","LoraConfig","MXFP4Layer","MatMul","QuantizeOntoGuard","StaticLoraConfig","UnquantLinear"],"trait":["BitWiseOp","CumSumOp","LeftshiftOp","NonZeroOp","QuantMethod","QuantizedSerde","SortOp"]};